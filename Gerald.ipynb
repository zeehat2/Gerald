{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.15+"
    },
    "colab": {
      "name": "Gerald.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCrjlUiOylNR",
        "colab_type": "code",
        "outputId": "6c108e7a-ed04-4fd9-8eb0-afd2f9ea2488",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAr7iclhrqYg",
        "colab_type": "text"
      },
      "source": [
        "Please excuse the formatting, haven't really done much markdown before. Anyway, we get started by importing some libraries, and loading in our data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIkNy1gGrqYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import re\n",
        "import numpy as np    \n",
        "import sklearn as sk\n",
        "import scipy as sp\n",
        "from sklearn import decomposition\n",
        "from sklearn import ensemble\n",
        "from nltk import PorterStemmer\n",
        "from scipy import sparse\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from tensorflow import keras as ks\n",
        "from tqdm import tqdm_notebook\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aySnnB6GrqY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "with open(\"drive/My Drive/gerald_data/train.json\") as file:\n",
        "  train_data = json.load(file)[::3]\n",
        "#with open(\"drive/My Drive/gerald_data/test.json\") as file:\n",
        "#  test_data = json.load(file)[::10]\n",
        "with open(\"drive/My Drive/gerald_data/stopwords.txt\") as file:\n",
        "  stopwords = file.read().splitlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oI8EqQXRrqY6",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing\n",
        "\n",
        "Like in assignment 2, lowercase this bad boy and remove the punctuation. Then remove stopwords and apply stemming."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jbCEZSTrqY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ps = PorterStemmer()\n",
        "def preprocess(post):\n",
        "  words = re.sub('[^a-z0-9 ]', '', post[\"post\"].lower()).split()\n",
        "  return list(map(ps.stem, filter(lambda w : w not in stopwords, words)))\n",
        "\n",
        "posts = [preprocess(post) for post in train_data]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivKNSI03rqZD",
        "colab_type": "text"
      },
      "source": [
        "Now we create our list of unique words. However, we also want to discard the nonsense, so we delete words from the list that occur in too few posts. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sd7OPXiWrqZF",
        "colab_type": "code",
        "outputId": "a1a52d18-d656-4ef5-80c0-abf1f63c61fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#TOO_RARE_THRESHOLD = 0.005  # Rate of occurence below which a word is too rare to be considered\n",
        "NUM_WORDS=5000\n",
        "\n",
        "words = dict()  # Match words to the number of posts they occured in.\n",
        "for post in posts:\n",
        "    for word in list(set(post)): # set trick removes duplicates\n",
        "        if word in words:\n",
        "             words[word] += 1\n",
        "        else:\n",
        "             words[word] = 1\n",
        "\n",
        "print \"Features before removal of rare words: %d\" % len(words)                \n",
        "#for word in words.keys():\n",
        "#    if words[word] < TOO_RARE_THRESHOLD * len(posts):\n",
        "#        del(words[word])\n",
        "words = sorted(words.keys(), key=words.get, reverse=True)[:NUM_WORDS]    # words is now a list, sorted by how many times each word occured.    \n",
        "\n",
        "\n",
        "print \"After removal: %d\" % len(words)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features before removal of rare words: 434836\n",
            "After removal: 2186\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE-X43E1UGpy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"drive/My Drive/gerald_data/vocab\", \"w\") as file:\n",
        "  pickle.dump(words, file)\n",
        "with open(\"drive/My Drive/gerald_data/posts\", \"w\") as file:\n",
        "  pickle.dump(posts, file)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5hnot3PWoSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAXLEN=500\n",
        "\n",
        "def vectorize_x(data):\n",
        "  pruned_data = [filter(lambda w:w in words, post) for post in data]\n",
        "  return ks.preprocessing.sequence.pad_sequences([[words.index(word) for word in post] for post in pruned_data], maxlen=MAXLEN)\n",
        "\n",
        "def vectorize_gender(data):\n",
        "  return np.array(map(lambda post : 1 if post[\"gender\"] == \"male\" else 0, data))  \n",
        "\n",
        "def vectorize_age(data):\n",
        "  return np.array([post['age'] for post in data])  \n",
        "\n",
        "X = vectorize_x(posts)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4D87VT9cBL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ks.models.Sequential()\n",
        "\n",
        "model.add(ks.layers.Embedding(len(words), 20, input_length=MAXLEN))\n",
        "#model.add(ks.layers.Dropout(0.2))\n",
        "#model.add(ks.layers.Flatten())\n",
        "model.add(ks.layers.Conv1D(100, 3, padding='valid', activation='elu'))\n",
        "model.add(ks.layers.Conv1D(100, 2, padding='valid', activation='elu'))\n",
        "#model.add(ks.layers.Dropout(0.2))\n",
        "model.add(ks.layers.Flatten())\n",
        "model.add(ks.layers.Dense(200, activation='elu'))\n",
        "model.add(ks.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_yt4KrHjXz3",
        "colab_type": "code",
        "outputId": "a275aebb-89f9-42cc-dbfe-953881be8ebe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "Y_gender = vectorize_gender(train_data)\n",
        "#print(X.shape, Y_gender.shape, len(words))\n",
        "model.summary()\n",
        "#model.build()\n",
        "model.fit(X, Y_gender, epochs=1, validation_split=0.1, batch_size=50)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 500, 20)           43720     \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 498, 100)          6100      \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 497, 100)          20100     \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 49700)             0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 200)               9940200   \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 10,010,321\n",
            "Trainable params: 10,010,321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 158043 samples, validate on 17561 samples\n",
            "158043/158043 [==============================] - 62s 394us/sample - loss: 0.6487 - acc: 0.6236 - val_loss: 0.6327 - val_acc: 0.6390\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f40d8d42d10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqCmgbWJLWj8",
        "colab_type": "code",
        "outputId": "f4e80e53-a449-4424-8e16-8bbba82d5794",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open(\"drive/My Drive/gerald_data/test.json\") as file:\n",
        "  test_data = json.load(file)\n",
        "\n",
        "X_test = vectorize_x([preprocess(post) for post in test_data])\n",
        "Y_test_gender = vectorize_gender(test_data)\n",
        "\n",
        "model.evaluate(X_test, Y_test_gender)  \n",
        "model.save(\"drive/My Drive/gerald_data/W_gender\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "131703/131703 [==============================] - 20s 153us/sample - loss: 0.6332 - acc: 0.6379\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAQ-qcMM7v5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ks.models.Sequential()\n",
        "\n",
        "model.add(ks.layers.Embedding(len(words), 20, input_length=MAXLEN))\n",
        "model.add(ks.layers.Dropout(0.2))\n",
        "#model.add(ks.layers.Flatten())\n",
        "model.add(ks.layers.Conv1D(150, 3, padding='valid', activation='elu'))\n",
        "model.add(ks.layers.Conv1D(100, 3, padding='valid', activation='elu'))\n",
        "model.add(ks.layers.Dropout(0.2))\n",
        "model.add(ks.layers.Flatten())\n",
        "model.add(ks.layers.Dense(200, activation='elu'))\n",
        "model.add(ks.layers.Dense(1, activation='relu'))\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjLagM397yaZ",
        "colab_type": "code",
        "outputId": "e6217ea2-5c48-492f-de72-8cec87ac6d7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        }
      },
      "source": [
        "Y_age = vectorize_age(train_data)\n",
        "print(X.shape, Y_age.shape, len(words))\n",
        "model.summary()\n",
        "#model.build()\n",
        "model.fit(X, Y_age, epochs=2, validation_split=0.1, batch_size=50)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "((175604, 500), (175604,), 2186)\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 500, 20)           43720     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 500, 20)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_10 (Conv1D)           (None, 498, 150)          9150      \n",
            "_________________________________________________________________\n",
            "conv1d_11 (Conv1D)           (None, 496, 100)          45100     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 496, 100)          0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 49600)             0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 200)               9920200   \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 10,018,371\n",
            "Trainable params: 10,018,371\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 158043 samples, validate on 17561 samples\n",
            "Epoch 1/2\n",
            "158043/158043 [==============================] - 80s 506us/sample - loss: 49.3478 - mean_absolute_error: 5.3303 - val_loss: 46.0692 - val_mean_absolute_error: 5.2353\n",
            "Epoch 2/2\n",
            "158043/158043 [==============================] - 79s 500us/sample - loss: 44.8722 - mean_absolute_error: 5.0818 - val_loss: 44.4930 - val_mean_absolute_error: 5.0334\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4053f68b50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOzr92T1ZYJ_",
        "colab_type": "code",
        "outputId": "34c747f3-f023-4d4f-86ac-f430ea268262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Y_test_age = vectorize_age(test_data)\n",
        "\n",
        "model.evaluate(X_test, Y_test_age) \n",
        "model.save(\"drive/My Drive/gerald_data/W_age\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "131703/131703 [==============================] - 26s 196us/sample - loss: 44.6770 - mean_absolute_error: 5.0201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sJGmKtmkUOg",
        "colab_type": "text"
      },
      "source": [
        "Next we define the functions we will use to vectorize our data, which we can then feed into some models!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tFij0Vwq9Ae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorize_x(data):\n",
        "  X = sp.sparse.lil_matrix((len(data), len(words)), dtype=np.int8)\n",
        "  for i, post in enumerate(data):\n",
        "    for word in list(set(post)):\n",
        "      try: \n",
        "        X.rows[i].append(words.index(word)) # In a lil_matrix, there is self.rows, where the ith element is a list of column indexes where there are non-zero elements...\n",
        "        X.data[i].append(1)                 # ...and self.data, where the ith element is a list of the non-zero elements that occur in that row.\n",
        "      except: pass\n",
        "    if i % 1000 == 0:\n",
        "      print i\n",
        "  return X.tocsr()\n",
        "  \n",
        "\n",
        "def vectorize_gender(data):\n",
        "  return np.array(map(lambda post : 1 if post[\"gender\"] == \"male\" else 0, data)) # Change genders to 1:male, 0:female\n",
        "\n",
        "def vectorize_age(data):\n",
        "  return np.array((post['age'] for post in data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IWtfjMolc7c",
        "colab_type": "text"
      },
      "source": [
        "Here we apply SVD to reduce the dimensionality of the data to something more managable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KM3HPnqeN6l",
        "colab_type": "code",
        "outputId": "34a76690-38d2-4db1-c23d-a45630b36396",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "N_COMPONENTS = 300\n",
        "\n",
        "svd = sk.decomposition.TruncatedSVD(N_COMPONENTS)\n",
        "Xtr_vec = vectorize_x(posts)\n",
        "X_train = svd.fit_transform(Xtr_vec) \n",
        "Xte_vec = vectorize_x([preprocess(post) for post in test_data])\n",
        "X_test = svd.transform(Xte_vec)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "10000\n",
            "11000\n",
            "12000\n",
            "13000\n",
            "14000\n",
            "15000\n",
            "16000\n",
            "17000\n",
            "18000\n",
            "19000\n",
            "20000\n",
            "21000\n",
            "22000\n",
            "23000\n",
            "24000\n",
            "25000\n",
            "26000\n",
            "27000\n",
            "28000\n",
            "29000\n",
            "30000\n",
            "31000\n",
            "32000\n",
            "33000\n",
            "34000\n",
            "35000\n",
            "36000\n",
            "37000\n",
            "38000\n",
            "39000\n",
            "40000\n",
            "41000\n",
            "42000\n",
            "43000\n",
            "44000\n",
            "45000\n",
            "46000\n",
            "47000\n",
            "48000\n",
            "49000\n",
            "50000\n",
            "51000\n",
            "52000\n",
            "0\n",
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "10000\n",
            "11000\n",
            "12000\n",
            "13000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFmY4SanmNgy",
        "colab_type": "text"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dX0V0JYmvbB",
        "colab_type": "code",
        "outputId": "7f292714-bc03-466e-f88b-468ade5547dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "Y_gender_train = vectorize_gender(train_data)\n",
        "Y_gender_test = vectorize_gender(test_data)\n",
        "\n",
        "bayes = BernoulliNB()\n",
        "bayes.fit(Xtr_vec, Y_gender_train)\n",
        "print \"Naive bayes train accuracy: {:.2%}\".format(bayes.score(Xtr_vec, Y_gender_train))\n",
        "print \"Naive bayes test accuracy: {:.2%}\".format(bayes.score(Xte_vec, Y_gender_test))\n",
        "\n",
        "#N_NEIGHBORS = 10\n",
        "#nn = sk.neighbors.KNeighborsClassifier(N_NEIGHBORS)\n",
        "#nn.fit(X_train, Y_gender_train)\n",
        "#print \"Nearest-neighbors train accuracy: {:.2%}\".format(nn.score(X_train, Y_gender_train))\n",
        "#print \"Nearest-neighbors test accuracy: {:.2%}\".format(nn.score(X_test, Y_gender_test))\n",
        "\n",
        "TREES = 100\n",
        "forest = sk.ensemble.RandomForestClassifier(n_estimators=TREES, max_depth=5)\n",
        "forest.fit(Xtr_vec, Y_gender_train)\n",
        "print \"Random forest train accuracy: {:.2%}\".format(forest.score(Xtr_vec, Y_gender_train))\n",
        "print \"Random forest test accuracy: {:.2%}\".format(forest.score(Xte_vec, Y_gender_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive bayes train accuracy: 60.42%\n",
            "Naive bayes test accuracy: 60.11%\n",
            "Random forest train accuracy: 59.97%\n",
            "Random forest test accuracy: 58.96%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}